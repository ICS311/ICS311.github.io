<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html> <head>
<title>ICS 311 #11: Balanced Trees </title>
</head>

<body>
<hr><h1><a href="../index.html">ICS 311</a> #11: Balanced Trees (2-4 and Red-Black)</h1><hr> 

<!-- ------------------------------------------------------------ -->
<h2>Outline</h2>
<ul> 
  <li>Balanced and Multi-Way Trees  </li>
  <li>2-4 Trees (also known as 2-3-4 or (2,4) trees)  </li>
  <li>Red-Black Trees
    <ul>
      <li>as a binary representation of 2-4 trees</li>
      <li>as binary search trees</li>
    </ul>
    </li> 
  <li>Insertion in Red-Black Trees</li>
  <li>Deletion in Red-Black Trees</li>
  <li>Comparison of Dictionary Implementations</li> 
</ul> 

<h2>Readings and Screencasts</h2>

<p>The presentation of Red-Black Trees (RBTs) in Cormen et al. omits a major
conceptual motivation: RBTs are a binary representation of a balanced multi-way
tree, and the complex operations on RBTs correspond to simpler operations on 2-4
trees. This motivation is nicely presented by Sedgewick, so read in this
order:</p>

<ul>
  <li> Sedgewick (1983) chapter 15 on Balanced Trees (posted in Laulima).</li>
  <li> CLRS Chapter 13 once you have understood RBTs in terms of 2-4 trees.</li>
  <li>Screencasts <a href="http://youtu.be/N-Sot-yf3As">11A</a>,
                  <a href="http://youtu.be/W49P7wqdIuE">11B</a>,
                  <a href="http://youtu.be/a6LaiKa3ES0">11C</a>,
                  <a href="http://youtu.be/HlwQ_n56MHQ">11D</a>
                  (also in Laulima and iTunesU)</li>
</ul>

<p>Although it is a good start, Sedgewick's presentation of 2-4 trees omits some
detail, so I draw on Goodrich & Tamassia's slides widely available on the Web
for the following presentation.</p>

<!-- ------------------------------------------------------------ -->
<hr><h2> Multi-Way Trees </h2>

<p>A <b>multi-way search tree</b> is an ordered tree such that </p>

<ul>
  
  <li>Each internal node has at least two children and stores <i>d</i>-1
     key-object pairs (<i>k<sub>i</sub></i>, <i>o<sub>i</sub></i>), where
     <i>d</i> is the number of children. </li>
  
  <li>For a node with children <i>v<sub>1</sub></i> <i>v<sub>2</sub></i>
     ... <i>v<sub>d</sub></i> storing keys <i>k<sub>1</sub></i>
     <i>k<sub>2</sub></i> ... <i>k<sub>d-1</sub></i>
  
    <ul>

      <li>keys in the subtree of <i>v<sub>1</sub></i> are less than
      <i>k<sub>1</sub></i></li>
      
      <li>keys in the subtree of <i>v<sub>i</sub></i> are between
      <i>k<sub>i-1</sub></i> and <i>k<sub>i</sub></i> (<i>i</i> = 2, ...,
      <i>d</i> - 1)</li>
      
      <li>keys in the subtree of <i>v<sub>d</sub></i> are greater than
      <i>k<sub>d-1</sub></i></li>
      
    </ul>
    
    <li>The leaves store no items and serve as placeholders</li>
    
</ul> 
<img src="Topic-11/GT-multiway-search-tree.jpg">

<p><b>Multi-way inorder traversal</b> can be defined by extension of BST inorder
traversal to visit the keys in increasing order:</p>

<blockquote>
Visit item (<i>k<sub>i</sub></i>, <i>o<sub>i</sub></i>) of node <i>v</i> between
the recursive traversals of the subtrees of <i>v</i> rooted at children
<i>v<sub>i</sub></i> and <i>v<sub>i+1</sub></i>.
</blockquote> 
<img src="Topic-11/GT-multiway-inorder-traversal.jpg">

<p><b>Searching</b> can similarly be extended to multi-way trees by searching
within each node as well as down the tree:</p>

<ul>
  <li> At each internal node with children <i>v<sub>1</sub></i> <i>v<sub>2</sub></i>
       ... <i>v<sub>d</sub></i> and keys <i>k<sub>1</sub></i> <i>k<sub>2</sub></i> 
       ... <i>k<sub>d-1</sub></i>:
  <ul>
    
      <li>if <i>k</i> = <i>k<sub>i</sub></i> (<i>i</i> = 1, ... , <i>d</i> - 1):
          the search terminates with success</li>
    
      <li>if <i>k</i> &lt; <i>k<sub>1</sub></i>: we continue the search in child
          <i>v<sub>1</sub></i></li>
          
      <li> if <i>k<sub>i-1</sub></i> &lt; <i>k</i> &lt; <i>k<sub>i</sub></i>
           (<i>i</i> = 2, ... , <i>d</i> - 1): we continue the search in child
           <i>v<sub>i</sub></i></li>
          
      <li> if <i>k</i> &gt; <i>k<sub>d-1</sub></i>: we continue the search in child
           <i>v<sub>d</sub></i></li>
           
    </ul>
  </li>
  
  <li>Reaching an external node terminates the search unsuccessfully</li>
  
</ul>

<p> For example, searching for key 30, we follow the red path:</p>
<img src="Topic-11/GT-multiway-searching.jpg">

<!-- ----------------------------------------------------------------------------- -->
<hr><h2>2-4 Trees</h2>

<p>Also known as (2,4) or 2-3-4 trees, these are multi-way trees restricted in
two ways: </p>

<ul>
  
  <li><b>Node Size Property</b>: every internal node has at least two children
  (one key) and at most four children (three keys).</li>
  
  <li><b>Depth Property</b>: all of the external nodes have the same depth. (The
  tree is balanced.)</li>
  
</ul>

<p>The internal nodes are called 2-nodes, 3-nodes or 4-nodes, depending on the
number of children they have.</p>

<img src="Topic-11/GT-2-4-trees.jpg">

<!-- ------------------------------------ -->
<h3>Height of 2-4 Trees and Searching</h3> 

<p><b><i>Theorem:</i> A 2-4 tree storing n items has height &Theta;(lg n).</b></p>

<p>Let <i>h</i> be the height of a 2-4 tree with <i>n</i> items. The proof is in
two parts, for the upper bound and the lower bound.</p>

<p><b><i>Upper bound:</i></b> The tallest possible tree for a fixed <i>n</i> is
when all internal nodes are 2-nodes, each storing 1 item; i.e., the tree is
equivalent to a binary tree. By the depth property, it is a complete binary
tree. (See also quantitative facts for complete binary trees in <a
href="Topic-08.html#binarytrees">Topic 8</a>, but we do the full proof here.)
</p>

<p> In such a tree, there are 1=1*2<sup>0</sup> items stored at depth 0,
2=1*2<sup>1</sup> items stored at depth 1, 4=1*2<sup>2</sup> items stored at
depth 2, or more generally 1*2<sup><i>i</i></sup> items at depth <i>i</i>. (I
include the "1*" to represent the number of items stored in a node, which will
change in the second part of the proof, but drop it now.) Since the last level
of a 2-4 tree of height <i>h</i> stores no items (see for example picture above)
we stop at <i>h</i>&minus;1. So the total number of nodes is
<big>&Sigma;</big><sub><i>i</i>=0,<i>h</i>&minus;1</sub>2<sup><i>i</i></sup>.</p>

<img src="Topic-11/formula-A-5.jpg" align = "right" border="1">

<p> Applying formula A5 (shown) with <i>h</i>&minus;1 for <i>n</i> and 2 for
<i>x</i>, the number <i>n</i> of nodes stored in the tallest 2-4 tree of height
<i>h</i> is: </p>

<blockquote> 
<big>&Sigma;</big><sub><i>i</i>=0,<i>h</i>&minus;1</sub>2<sup><i>i</i></sup> <br>

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = (2<sup>(h&minus;1)+1</sup> &minus; 1)/(2&minus;1) <br>

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = 2<sup><i>h</i></sup> &minus; 1,<br> <br> 

so <br> &nbsp; &nbsp; &nbsp; &nbsp; <i>n</i> = 2<sup><i>h</i></sup> &minus; 1 &nbsp; or &nbsp; n + 1 &ge;
2<sup><i>h</i>

</blockquote> 

<p>Taking the log base 2 of both sides: &nbsp; lg (<i>n</i> + 1) &ge;
<i>h</i>. &nbsp; Thus, <b> <i>h</i> = O(lg <i>n</i>).</b> </p>

<p><b><i>Lower bound:</i></b> The shortest possible tree for a fixed <i>n</i> is
when all internal nodes are 4-nodes, each storing 3 items (by the size
property). By the depth property, all levels are filled out. The proof is
similar to above but with different constants:</p>

<p> There are 3=3*4<sup>0</sup> items stored at depth 0, 12=3*4<sup>1</sup>
items stored at depth 1, 48=3*4<sup>2</sup> items stored at depth 2, or more
generally 3*4<sup><i>i</i></sup> items at depth <i>i</i>. Since the last level
of a 2-4 tree of height <i>h</i> stores no items we stop at <i>h</i>&minus;1. So
the total number of nodes is
<big>&Sigma;</big><sub><i>i</i>=0,<i>h</i>&minus;1</sub>3*4<sup><i>i</i></sup>.
Moving the 3 out and applying formula A5, </p>

<blockquote> 
<big>3*&Sigma;</big><sub><i>i</i>=0,<i>h</i>&minus;1</sub>4<sup><i>i</i></sup> <br>

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = 3*(4<sup>(h&minus;1)+1</sup>&minus; 1)/(4&minus;1) <br>

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; = 4<sup><i>h</i></sup>&minus;1, <br>

so <br> &nbsp; &nbsp; &nbsp; &nbsp; <i>n</i> = 4<sup><i>h</i></sup>&minus;1 &nbsp;
or &nbsp;  n + 1 = 4<sup><i>h</i></sup></p>
</blockquote>

<p>Taking the log base 4 of both sides: &nbsp; log<sub>4</sub> (<i>n</i> + 1) =
<i>h</i>.<br> Since the base of logarithms differs only by a constant factor
(see 3.15 of text), in this case by log<sub>2</sub>4 = 2, <b> <i>h</i> =
&Omega;(lg <i>n</i>).</b> </p>

<p>Putting these results together, <b><i>h</i> = &Theta;(lg <i>n</i>).</b></p>

<p>Since searching in a 2-4 tree with <i>n</i> items requires time proportional
to a path from root to leaves, <b>searching requires O(lg <i>n</i>)</b>
time.</p>

<!-- ------------------------------------ -->
<h3>2-4 Tree Insertion</h3>

<p>We will examine insertion and deletion briefly to understand the conceptual
cases. </p>

<p>Insert a new item keyed by <i>k</i> into the <u>parent of the leaf reached by
searching for <i>k</i></u>, and adding an empty leaf node below.</p>

<p>(<i>This differs from binary search trees, which put the key into a new node
below the leaf node reached. Here we insert into the parent of leaf because we
don't put data in the leaves.</i>)</p>

<p>This preserves depth but may cause <b>overflow</b> (a node may become a
5-node).</p>

<p><i>Example:</i> Inserting 30, we find its position between 27 and 32. However
inserting here causes overflow:</p>

<img src="Topic-11/GT-2-4-tree-insertion.jpg">

<p>Overflow is handled with a <b>split operation</b>, as illustrated below with
a simpler tree:</p>

<ul>

  <li>The 5-node containing keys <i>k<sub>1</sub></i>, <i>k<sub>2</sub></i>,
      <i>k<sub>3</sub></i>, <i>k<sub>4</sub></i> is split into a 3-node with
      keys <i>k<sub>1</sub></i>, <i>k<sub>2</sub></i> and a 2-node with key
      <i>k<sub>4</sub></i>.</li>
  
  <li>Key <i>k<sub>3</sub></i> is inserted into the parent node (as would be the
      case with the tree above).</li>
      
  <li>Overflow may propagate to the parent node. (This would happen in the tree
      pictured above.)</li>
      
  <li>A new root may be created if the root overflows.</li>
      
</ul>
<img src="Topic-11/GT-2-4-tree-overflow-split.jpg">

<p><i>(Note: Sedgewick splits 4-nodes on the way down while searching for the
insertion position, guaranteeing that there will be no overflow. Both Goodrich &
Tamassia and Cormen et al. take the other approach, propagating splits upwards
only as needed. The asymptotic time complexity remains the same.)</i></p>

<h4>Time Complexity of 2-4 Insertion</h4>

<p>A tree with <i>n</i> items has &Theta;(lg <i>n</i>) height. The algorithm
first searches for the insertion location, which requires visiting <i>h</i> =
&Theta;(lg <i>n</i>) nodes (&Theta;, not O, because we must go to the leaves in
all cases). The insertion takes &Theta;(1) time.</p>

<p>If there is overflow, splits (taking &Theta;(1) time each) may be propagated
upwards to as many as O(lg <i>n</i>) nodes. Since the &Theta;(lg <i>n</i>)
overrides the possibility of slower growing functions in O(lg <i>n</i>),
insertion is <b>&Theta;(lg <i>n</i>)</b>.</p>

<!-- ------------------------------------ -->
<h3>2-4 Tree Deletion</h3>

<p>If the entry to be deleted is in a node that has internal nodes as children,
we replace the entry to be deleted with its inorder successor and delete the
latter entry.  Example: to delete key 24, we replace it with 27 (inorder
successor): </p>

<img src="Topic-11/GT-2-4-tree-deletion.jpg">

<p>This reduces deletion of an entry to the case where the item is at the node
with leaf children.</p>

<p>Deletion of an entry from a node <i>v</i> may cause <b>underflow,</b> where
node <i>v</i> becomes a 1-node with one child and no keys. Underflow at node
<i>v</i> with parent <i>u</i> is handled in two cases. </p>

<p><b><i>Case 1</i></b>: An adjacent sibling of <i>v</i> is a 2-node. Perform a
<b>fusion operation</b>, merging <i>v</i> with the adjacent 2-node sibling
<i>w</i> and moving a key from <i>u</i> to the merged node <i>v'</i>.</p>

<img src="Topic-11/GT-2-4-tree-underflow-fusion.jpg">

<p>After a fusion, the underflow may propagate to the parent u, for at most O(lg
<i>n</i>) adjustments up the tree.</p>

<p><b><i>Case 2</i></b>: An adjacent sibling <i>w</i> of <i>v</i> is a 3-node or
a 4-node. Perform a <b>transfer operation:</b> move a key from <i>u</i> to
<i>v</i>; and a key from <i>w</i> to <i>u</i>:</p>

<img src="Topic-11/GT-2-4-tree-underflow-transfer.jpg">

<p>The underflow is eliminated. (Which keys are moved depends on the
configuration. In this example we move the largest key out of each node, but it
could be different if underflow was in a non-rightmost child or it was a right
sibling that was a 3-node or 4-node.) </p>

<h4>Time Complexity of 2-4 Deletion</h4>

<p>The algorithm first searches for the item to delete, which requires visiting
<i>h</i> = &Theta;(lg <i>n</i>) nodes on the way down the tree, either to find a
bottom level key to delete, or to find the successor of a key in an internal
node to delete. Underflow is handled with up to O(lg <i>n</i>) fusions and
transfers, each taking &Theta;(1) time. Thus deletion is <b>&Theta;(lg
<i>n</i>)</b>.</p>

<!-- ------------------------------------------------------------ -->
<hr><h2> Red-Black Trees </h2>

<p>Sedgewick motivates the transition to red-black trees by noting it would be
complex to manage different kinds of nodes (2, 3, and 4), but we already have
a tree representation (binary search trees) that, with the addition of one bit
per node can represent 2-4 trees: Red-Black Trees.</p>

<!-- ------------------------- -->
<h3>Red-Black Tree Properties</h3>

<img src="Topic-11/Simple-Red-Black-Tree.jpg" align = "right">

<p>A red-black tree (RBT) is a binary search tree with the following additional
properties:</p>

<ol>

  <li><b>Color property</b>: Every node is either red or black. <i>(We can
      indicate this either by coloring the node or by coloring its parent
      link.)</i> </li>
      
  <li><b>Root property</b>: The root is black</li>
  
  <li><b>External property</b>: Every leaf is black.</li>
  
  <li><b>Internal property</b>: If a node is red, then both of its children are
      black. <i>(Hence, no two reds in a row are allowed on a simple path from
      the root to a leaf.)</i></li>
      
  <li><b>Depth property</b>: For each node, all the paths from the node to
      descendant leaves contain the same number of black nodes (the <b>black
      height</b> of the node).</li>
  
</ol>

<p>These properties seem rather arbitrary until we consider the correspondence
with 2-4 trees shortly, but first please verify how the properties hold in this
example (where red is represented by grey) ... </p>

<img src="Topic-11/Fig-13-1-RBT-Representation-a.jpg">

<!-- ------------------------- -->
<h3>Red-Black Tree Representation</h3>

<p>A single extra bit is required on each node to mark it as "red" or
"black".</p>

<p>To save space, we can represent the leaf nodes <i>and</i> the parent of the
root node with a single node, T.nil:</p>

<img src="Topic-11/Fig-13-1-RBT-Representation-b.jpg">

<p> This also simplifies the code, as we can follow pointers without having to
check for null pointers.</p>

<p>We usually don't draw T.nil: </p> 
<img src="Topic-11/Fig-13-1-RBT-Representation-c.jpg">

<!-- ---------------------------------------------- -->
<h3>RBTs as a Binary Representation of 2-4 Trees</h3>

<p>It would be rather complex to implement and manipulate 2-nodes, 3-nodes and
4-nodes. One motivation for red-black trees is that they provide a binary tree
representation of 2-4 trees, enabling us to manipulate only one kind of
node. (The motivation for starting with 2-4 trees rather than just going to RBTs
directly is that, considered on their own, RBT manipulations are complex and
hard to understand, as you will find out when you read CLRS.) The mapping is as
follows: </p>

<center>
<img src="Topic-11/GT-From-2-4-to-RBT.jpg">

<p><b>Red nodes (and the links from their parents) capture the <i>internal
structure of a (2,3) node</i>;</b></p>

<p><b>Black nodes (and the links from their parents) capture the <i>structure of
the (2,3) tree</i> itself.</b> </p>

<p> <u>You should make sure you understand this well before going
on!</u></p>
</center>

<!-- --------------------------- -->
<h3>RBTs as Binary Search Trees</h3>
            
<p>At the same time as they represent 2-4 trees, <i><b>RBTs are also Binary
Search Trees</b></i>: they satisfy the Binary Search Tree property. For example,
here is a RBT: we can search for keys or enumerate elements in order as
usual:</p>

<img src="Topic-11/GT-RBTs.jpg">

<p>In order to maintain the Red-Black-Tree properties, it will be necessary to
do structural rotations. These rotations are designed to not disrupt the BST
property. For example, this rotation does not disturb the BST ordering of keys
9, 11, 12, 14, 17, 18, 19 <i>(you should verify this before reading on)</i>:</p>
<img src="Topic-11/Fig-13-3-Rotation-BST.jpg">

<h4>Height of Red-Black Trees and Searching</h4> 

<p><b>Theorem: A red-black tree storing n items has height &Theta;(lg
<i>n</i>).</b> </p>

<p><i>Proof:</i></p>
<ul>

  <li> Let <i>h</i> be the height of a red-black tree with <i>n</i> items</li>

  <li> By property 4, there cannot be more red nodes (and links) on a simple
       path from the root to a leaf than there are black nodes (and
       links). </li>

  <li> Therefore the black height of the root of the tree is between <i>h</i>
       and <i>h</i>/2.</li> 
       
  <li> The black height of the root of the red-black tree corresponds to the
       height <i>h'</i> of the 2-4 tree that the red-black tree represents
       (since red nodes/links in the RBT represent the internal structure of the
       nodes in the 2-4 tree). </li>
       
  <li> From the theorem concerning the height of 2-4 trees, <i>h'</i> is
       &Theta;(lg <i>n</i>). </li>
 
 <li> Since <i>h</i> is no more than twice <i>h'</i>, <i>h</i> is also
      &Theta;(lg <i>n</i>).</li>
 
</ul>

<p>(See Cormen et al. for a proof not relying on 2-4 trees.)</p> 

<p>Therefore, searching in a red-black tree with <i>n</i> items takes <b>O(lg
<i>n</i>)</b> time (O rather than &Theta; as we may find the key in an internal
node). </p>

<p>We now consider insertion and deletion. Please see the CLRS textbook for the
many details of implementation in pseudocode, etc.: here we will concentrate on
seeing how the RBT operations correspond to 2-4 tree operations.</p>

<!-- ------------------------------- -->
<h3> Insertion in Red-Black Trees </h3>

<p>To insert an element with key <i>k</i>, perform the insertion for binary
search trees (except that conceptually we insert <i>k</i> in an internal node
with null children, not at a leaf node), and color the newly inserted node
<i>z</i> red, unless it is the root.</p>

<p>This preserves the color, root, external, and depth properties. <em>(You
should check this in the example below.)</em></p>

<p>If the parent <i>v</i> of <i>z</i> is black, this also preserves the internal
property and we are done.</p> <p>Else (<i>v</i> is red), we have a <b>double
red</b> (i.e., a violation of the internal property), which requires a
reorganization of the tree. For example, insert 4:</p>

<img src="Topic-11/GT-RBT-insertion.jpg">

<p>A double red with child <i>z</i> and parent <i>v</i> is dealt with in two
cases. Let <i>w</i> be the sibling of <i>v</i> (and hence the uncle of
<i>z</i>).</p>

<p><b><i>Case 1:</i></b> <i>w</i> is black. The double red is an <i><b>incorrect
representation</b></i> of a 4-node. We will fix this with
<i>restructuring</i>. For example, the RBT on the left is an incorrect
representation of the 2-4 tree on the right:</p>

<img src="Topic-11/GT-RBT-double-red-case-1.jpg">

<p><b><i>Case 2:</i></b> w is red.  The double red corresponds to an
<i><b>overflow</b></i> in the 2-4 tree. We will fix this with <i>recoloring</i>,
which is the equivalent of a 2-4 split. For example:</p>

<img src="Topic-11/GT-RBT-double-red-case-2.jpg">

<h4>Restructuring</h4>

<p><b>Restructuring</b> remedies a child-parent double red when the parent red
node has a black sibling. It restores the correct representation (internal
property) of a 4-node, leaving other RBT and BST properties intact: </p>

<img src="Topic-11/GT-RBT-restructuring.jpg">

<p>There are four restructuring configurations depending on whether the double
red nodes are left or right children. They all lead to the same end
configuration of a black with two red children:</p>

<img src="Topic-11/GT-RBT-restructuring-configurations.jpg">

<p>After a restructuring, the double red has been remedied without violating any
of the other properties <em>(you should verify this)</em>: there is no need to
propagate changes upwards.</p>

<p>Notice that the height of the subtree tree has been reduced by
one. <b><em>This is the operation that keeps the trees balanced to within a
constant factor of lg(<i>n</i>) height</em></b>, by ensuring that the height of
the RBT is no more than twice that of the (necessarily balanced) 2-4 tree it
represents. <em>Do you see why?</em> </p>

<h4>Recoloring</h4> 

<p><b>Recoloring</b> remedies a child-parent double red when the parent red node
has a red sibling. The parent <i>v</i> and its sibling <i>w</i> become black and
the grandparent <i>u</i> becomes red, unless it is the root. We recolor a
non-root grandparent in order to maintain equal black height (in case the
grandparent has a sibling).</p>

<p>Recoloring is equivalent to performing a split on a 5-node in a 2-4
tree. (When there is a double red and yet another red in the parent's sibling,
we are trying to collect too many keys under the grandparent.) For example, the
RBT recoloring on the top corresponds to the 2-4 transformation on the
bottom:</p>

<img src="Topic-11/GT-RBT-recoloring.jpg">

<p>Notice that in this example the parent "4" is now red, meaning it belongs to
its parent node in the 2-4 tree. The double red violation may propagate to this
parent in the RBT, which corresponds to the overflow propagating up the 2-4
tree, requiring further repair.</p>

<p> Be aware that 3-nodes and overloaded nodes have more than one possible
representation as a red-black tree, and in particular this affects which key is
promoted by the recoloring. For example, the above overloaded 2-4 node of keys
{2, 4, 6, 7} can also be represented by either of the following trees, and you
can easily verify that recoloring will promote the key 6 in the 2-4 tree.</p>

<img src="Topic-11/RBT-recoloring-alternate-cases.jpg">

<h4>Time Complexity of RBT Insertion</h4>

<p>We already established that insertion in 2-4 trees is &Theta;(lg <i>n</i>)
due to their height. Since RBTs are only at most twice as high, we might expect
this result to transfer, and it does, but it needs to be shown separately since
the manipulations of the RBT are different. So: </p>

<ul>

  <li> The algorithm first searches for the insertion location, which will
       require visiting <i>h</i> = &Theta;(lg <i>n</i>) nodes on the way down
       the tree (since we are searching for a leaf node and the tree is
       balanced).</li>

  <li> Adding the item takes O(1). </li>

  <li> Recolorings and restructurings are &Theta;(1) each, and we perform at
       most O(lg <i>n</i>) recolorings and <em>one</em> restructuring
       propagating structural changes back up the tree.</li>

</ul>

<p>Thus insertion is <b>&Theta;(lg <i>n</i>).</b></p> 

<p>Note: A top-down version of this algorithm is also possible, restructuring on
the way down and requiring only one pass through the tree. See the Sedgewick
reading distributed.</p>

<!-- ----------------------------- -->
<h3> Deletion in Red-Black Trees </h3>

<p>To remove item with key <i>k</i>, we first perform the BST deletion (modified
for our representational changes using T.nil).</p>

<p>Because deletion of a node higher in the tree involves replacing it with its
successor, which is then deleted, deletion may involve an internal and an
external node.</p>

<p> We can preserve the RBT properties at the new internal location of the
successor by giving the successor the color of the node deleted, so we need only
be concerned with possible violations of RBT properties at the bottom of the
tree, where the successor was moved from, or where a node without a successor
was deleted. </p>

<p>Let <i>v</i> be the internal node removed, <i>w</i> the external node
removed, and <i>r</i> the sibling of <i>w</i>:</p>

<pre>
    x       
     \               x                    
      v       ==>     \
     / \               r 
    r   w
</pre> 

<p>If either <i>v</i> or <i>r</i> was red, we color <i>r</i> black and we are
done (the number of black nodes has not changed).</p>

<p>Else (<i>v</i> and <i>r</i> were both black), we have removed a black node,
violating the depth property. We "fix" this by coloring <i>r</i> <b>double
black,</b> a fictional color. (Intuitively, the black of both <i>v</i> and
<i>r</i> have been absorbed into <i>r</i>.) Now we have the correct "amount" of
black on this path from root to leaf, but the double black violates the color
property. </p>

<p>Fixing this will require a reorganization of the tree. Example: deletion of 8
causes a double black:</p>

<img src="Topic-11/GT-RBT-deletion-double-black.jpg">

<p>A double black corresponds to <i><b>underflow</b></i> in 2-4 trees (and here
the images I am borrowing from Goodrich &amp; Tamassia go to greyscale!):</p>
<img src="Topic-11/GT-double-black-as-underflow.jpg">

<p>Goodrich &amp; Tamassia's algorithm for remedying a <u>double black node
<i>r</i> with sibling <i>y</i></u> considers <u>three cases</u>, discussed
below. <em>(Note that these are different from CLRS's four cases!)</em></p>

<p><b><i>Case 1:</i></b> <i>y</i> is black and has a red child: Perform a RBT
<b>restructuring</b>, equivalent to a 2-4 <b>transfer</b>, and we are done.</p>

<p>For example, if we have the RBT on the left corresponding to underflow in the
2-4 tree on the right: </p>

<img src="Topic-11/GT-RBT-DB-remedy-case-1-1.jpg">

<p>... we do the following restructuring: </p>

<img src="Topic-11/GT-RBT-DB-remedy-case-1-2.jpg">

<p><b><i>Case 2:</i></b> <i>y</i> is black and its children are both black:
Perform a RBT <b>recoloring</b>, equivalent to a 2-4 <b>fusion</b>, which may
propagate up the double black violation.</p>

<p>If the double-black reaches the root we can just remove it, as it is now on
<em>all</em> of the paths from the root to the leaves, so does not affect
property 5, the depth property.</p>

<p>For example, if we have the RBT on the left corresponding to underflow in the
2-4 tree on the right: </p>

<img src="Topic-11/GT-RBT-DB-remedy-case-2-1.jpg">

<p>... we do the following recoloring: the black node <i>y</i> is colored red,
and the double black node <i>r</i> is colored ordinary black: </p>

<img src="Topic-11/GT-RBT-DB-remedy-case-2-2.jpg">

<p>The root of the above subtree takes on an extra black, which propagates only
if it was previously black and is not the root. If it was red it merely turns
black; if it was the root the extra black no longer affects the balanced black
height of the tree.</p>

<p><b><i>Case 3:</i></b> <i>y</i> is red: Perform a RBT <b>adjustment</b>,
equivalent to choosing a different representation of a 3-node, after which
either Case 1 or Case 2 applies.</p>

<img src="Topic-11/GT-RBT-DB-remedy-case-3.jpg">

<p> These are both representations of the following 2-4 tree, but the
transformation allows one of the other cases to apply, reducing duplication of
cases.</p>
<img src="Topic-11/GT-RBT-DB-remedy-case-3-2-4.jpg">

<p>The CLRS chapter divides the situation up into four cases: try to see whether
you can map between the above cases and theirs!</p>

<h4>Time Complexity of RBT Deletion</h4>

<p>The analysis is similar to the previous ones: &Theta;(lg <i>n</i>) search to
find the deletion point (the item to delete may be in an internal node, but we
always find its successor in any case, which is at the bottom of the tree),
followed by deletion and restructuring O(1) operations that are propagated at
most up O(lg <i>n</i>) levels. Deletion is <b>&Theta;(lg <i>n</i>)</b>. </p>

<!-- ----------------------- --> 
<h3>RBT Animation</h3>

<p>You may want to look at these:</p>
<dl>

  <dt> <a href="https://www.cs.usfca.edu/~galles/visualization/RedBlack.html">
    https://www.cs.usfca.edu/~galles/visualization/RedBlack.html </a></dt> 

  <dd> Step by step simulation with various controls. You add the nodes and see
  what happens. <b>Warning:</b> Their algorithm differs from CLRS, so don't use
  this to check your solutions unless you understand the difference!</dd> <br>
    
  <dt> <a
href="http://www.csanimated.com/animation.php?t=Red-black_tree">http://www.csanimated.com/animation.php?t=Red-black_tree</a>
</dt>

  <dd> A flash animation: slides with voice-over. It goes kind of fast (little
    time to figure out what property is being fixed in each case), and does not
    let you control slide by slide. </dd>

  </dl> 

<!-- ----------------------------------------------------------------------- --> 
<hr><h2>Related Data Structures</h2>

<p><b>AVL Trees,</b> named for their authors, are the oldest balanced
trees. They are binary trees with the requirement that the heights of the left
and right subtree of any given node differ at most by 1. A small amount of extra
storage is needed to record height differences. Their operations are O(lg
<i>n</i>) like RBTs, but may require O(lg <i>n</i>) rotations to rebalance. </p>

<p><b>Splay Trees</b> are binary trees in which an adjustment moving a node
towards the root called <i>splaying</i> is done after every access (including
search). There are no rules about properties to maintain and no
labels. Amazingly, splaying alone is enough to guarantee O(lg <i>n</i>) behavior
in an amortized sense: we will use these as an example when we cover chapter 17
Amortized analysis. They also make frequently accessed items more
accessible, which can be hugely useful in some applications. </p>

<p><b>B-Trees,</b> covered in Chapter 18 of Cormen et al. (but not in this
course), are balanced multi-way trees that allow up to M keys per node for large
M. They are used for trees in external (disk) storage, where speed is optimized
by making the size of a node be the same as the size of a block read in by one
disk read.</p>


<!-- ------------------------------------------------------------ -->
<hr><h2> Comparison of Dictionary Implementations </h2>
<p>First, here is a summary of the correspondence between 2-4 and Red-Black tree operations:</p>
<table width="100%" border="1">
  <tr>
    <th colspan="3" scope="col"><div align="left">Insertion: Remedy double red</div></th>
  </tr>
  <tr>
    <th scope="row"><div align="left">2-4 tree action</div></th>
    <td><div align="left"><strong>Red-Black Tree Action</strong></div></td>
    <td><div align="left"><strong>Result</strong></div></td>
  </tr>
  <tr>
    <td>Change of 4-node representation</td>
    <td>Restructuring</td>
    <td>Double red removed</td>
  </tr>
  <tr>
    <td>Split</td>
    <td>Recoloring</td>
    <td>Double red removed or propagated up</td>
  </tr>
  <tr>
    <th colspan="3" scope="row">&nbsp;</th>
  </tr>
  <tr>
    <th colspan="3" scope="row"><div align="left">Deletion: Remedy double black</div></th>
  </tr>
  <tr>
    <th scope="row"><div align="left">2-4 tree action</div></th>
    <td><strong>Red-Black Tree Action</strong></td>
    <td><strong>Result</strong></td>
  </tr>
  <tr>
    <td>Transfer</td>
    <td>Restructuring</td>
    <td>Double black removed</td>
  </tr>
  <tr>
    <td>Fusion</td>
    <td>Recoloring</td>
    <td>Double black removed or propagated up</td>
  </tr>
  <tr>
    <td>Change of 3-node representation</td>
    <td>Adjustment</td>
    <td>Restructuring or recoloring follows</td>
  </tr>
</table>

<p>A comparison of run times.<p> 
<table width="100%" border="1">
  <tr>
    <th scope="col">&nbsp;</th>
    <th scope="col">Search</th>
    <th scope="col">Insert</th>
    <th scope="col">Delete</th>
    <th scope="col">Notes</th>
  </tr>
  <tr>
    <th scope="row">Hash Table</th>
    <td>O(1) expected</td>
    <td>O(1) expected</td>
    <td>O(1) expected</td>
    <td><p>No ordered dictionary methods. Simple to implement.</p>
    </td>
  </tr>
  <tr>
    <th scope="row">Doubly Linked List</th>
    <td>O(<i>n</i>)</td>
    <td>O(1) if not sorted; O(<i>n</i>) if sorted </td>
    <td>&Theta;(1) if node given, O(<i>n</i>) otherwise</td>
    <td>Simple to implement.</td>
  </tr>
  <tr>
    <th scope="row">Skip List</th>
    <td>O(lg <i>n</i>) with high probability</td>
    <td>O(lg <i>n</i>) with high probability</td>
    <td>O(lg <i>n</i>) with high probability</td>
    <td>Randomized insertion. Simple to implement.</td>
  </tr>
  <tr>
    <th scope="row">Binary Tree</th>
    <td>O(<i>n</i>) worst case, O(lg <i>n</i>) random </td>
    <td>O(<i>n</i>) worst case, O(lg <i>n</i>) random </td>
    <td>O(<i>n</i>) worst case, O(lg <i>n</i>) random </td>
    <td>Moderately complex to implement deletion.</td>
  </tr>
  <tr>
    <th scope="row">Red-Black Tree</th>
    <td>O(lg <i>n</i>) worst case</td>
    <td>&Theta;(lg <i>n</i>)</td>
    <td>&Theta;(lg <i>n</i>) </td>
    <td>Complex to implement.</td>
  </tr>
</table>

<p>From this we can see that hash tables have the most efficient expected
behavior when no ordered methods are needed, and red-black trees give us the
best guarantee when ordering matters, although skip lists are a viable
alternative if you have to implement it yourself and want simpler code. But
there is good news! <b><a
href="https://docs.oracle.com/javase/7/docs/api/java/util/TreeMap.html"> Java
trees implement the CLRS algorithms for red-black trees! </a> </b>"Algorithms are
adaptations of those in Cormen, Leiserson, and Rivest's Introduction to
Algorithms."  You don't have
to do it!</p>

<!-- ------------------------------------------------------------ -->
<hr>
<address>Dan Suthers</address>
<!-- hhmts start -->Last modified: Tue Oct 20 15:24:47 HST 2020 <!-- hhmts end -->
<br>Images are from lecture slides provided by Michael Goodrich and Roberto Tamassia, and from the
instructor's material for Cormen et al. Introduction to Algorithms, Third Edition.</br>
</body>
</html>
